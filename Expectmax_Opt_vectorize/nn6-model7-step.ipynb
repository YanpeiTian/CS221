{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN2048(nn.Module):\n",
    "    def __init__(self, input_size=16, filter1=512, filter2=4096, drop_prob=0.):\n",
    "        super(NN2048, self).__init__()\n",
    "        self.conv_a = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(2,1), padding=0)\n",
    "        self.conv_b = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,2), padding=0)\n",
    "        self.conv_c = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(2,2), padding=0)\n",
    "        \n",
    "        self.conv_aa = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_ab = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.conv_ba = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_bb = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.conv_cc = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,2), padding=0)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.W_aa = nn.Linear(filter2 * 8, 1)\n",
    "        self.W_ab = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_ba = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_bb = nn.Linear(filter2 * 8, 1)\n",
    "        self.W_cc = nn.Linear(filter2 * 4, 1)\n",
    "\n",
    "    def flatten(self, x):\n",
    "        N = x.size()[0]\n",
    "        return x.view(N, -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        a = self.relu(self.conv_a(x))\n",
    "        b = self.relu(self.conv_b(x))\n",
    "        c = self.relu(self.conv_c(x))\n",
    "        aa = self.flatten(self.relu(self.conv_aa(a)))\n",
    "        ab = self.flatten(self.relu(self.conv_ab(a)))\n",
    "        ba = self.flatten(self.relu(self.conv_ba(b)))\n",
    "        bb = self.flatten(self.relu(self.conv_bb(b)))\n",
    "        cc = self.flatten(self.relu(self.conv_cc(c)))\n",
    "        out = self.W_aa(aa) + self.W_ab(ab) + self.W_ba(ba) + self.W_bb(bb) + self.W_cc(cc)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input(grid):\n",
    "    r = np.zeros(shape=(16, 4, 4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            r[grid[i, j],i, j]=1\n",
    "    return r\n",
    "\n",
    "def add_two(mat):\n",
    "    indexs=np.argwhere(mat==0)\n",
    "    index=np.random.randint(0,len(indexs))\n",
    "    mat[tuple(indexs[index])] = 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleScore=[0,0,4,16,48,128,320,768,1792,4096,9216,20480,45056,98304,212992,458752,983040]\n",
    "moveDict=np.load('move.npy')\n",
    "\n",
    "def move(list):\n",
    "    return moveDict[list[0],list[1],list[2],list[3],:]\n",
    "\n",
    "def lookup(x):\n",
    "    return singleScore[x]\n",
    "\n",
    "lookup = np.vectorize(lookup)\n",
    "\n",
    "def getScore(matrix):\n",
    "    return np.sum(lookup(matrix))\n",
    "\n",
    "def getMove(grid):\n",
    "    board_list = []\n",
    "    for i in range(4):\n",
    "        newGrid=moveGrid(grid, i)\n",
    "        if not isSame(grid,newGrid):\n",
    "            board_list.append((newGrid, i, getScore(newGrid)))\n",
    "    return board_list\n",
    "        \n",
    "def moveGrid(grid,i):\n",
    "    # new=np.zeros((4,4),dtype=np.int)\n",
    "    new = None\n",
    "    if i==0:\n",
    "        # move up\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==1:\n",
    "        # move left\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int)\n",
    "    elif i==2:\n",
    "        # move down\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==3:\n",
    "        # move right\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int)\n",
    "    return new\n",
    "\n",
    "def isSame(grid1,grid2):\n",
    "    return np.all(grid1==grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vchange(grid, v):\n",
    "    g0 = grid\n",
    "    g1 = g0[:,::-1,:]\n",
    "    g2 = g0[:,:,::-1]\n",
    "    g3 = g2[:,::-1,:]\n",
    "    r0 = grid.swapaxes(1,2)\n",
    "    r1 = r0[:,::-1,:]\n",
    "    r2 = r0[:,:,::-1]\n",
    "    r3 = r2[:,::-1,:]\n",
    "    xtrain = np.array([g0,g1,g2,g3,r0,r1,r2,r3])\n",
    "    ytrain = np.array([v]*8)\n",
    "    return xtrain, ytrain\n",
    "\n",
    "def gen_sample_and_learn(model, optimizer, loss_fn, is_train = False, explorationProb=0.1):\n",
    "    model.eval()\n",
    "    game_len = 0\n",
    "    game_score = 0\n",
    "    last_grid1 = np.zeros((4,4),dtype=np.int)\n",
    "    last_grid1 = add_two(last_grid1)\n",
    "    last_grid2 = make_input(last_grid1)\n",
    "    last_loss = 0\n",
    "\n",
    "    while True:\n",
    "        grid_array = add_two(last_grid1)\n",
    "        board_list = getMove(grid_array)\n",
    "        if board_list:\n",
    "            boards = np.array([make_input(g) for g,m,s in board_list])\n",
    "            p = model(torch.from_numpy(boards).cuda()).flatten().detach()        \n",
    "            game_len += 1\n",
    "            best_v = None\n",
    "            for i, (g,m,s) in enumerate(board_list):\n",
    "                v = (s - game_score) + p[i].item()\n",
    "                if best_v is None or v > best_v:\n",
    "                    best_v = v\n",
    "                    best_score = s\n",
    "                    best_grid1 = board_list[i][0]\n",
    "                    best_grid2 = boards[i]\n",
    "                    \n",
    "        else:\n",
    "            best_v = 0\n",
    "            best_grid1 = None\n",
    "            best_grid2 = None\n",
    "            \n",
    "        if is_train:\n",
    "            x, y = Vchange(last_grid2, best_v)\n",
    "            x = torch.from_numpy(x).cuda()\n",
    "            y = torch.from_numpy(y).unsqueeze(dim=1).cuda().float()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            last_loss = loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "                \n",
    "        if not board_list:\n",
    "            break\n",
    "            \n",
    "        # gibbs sampling or espilon-greedy\n",
    "        if is_train and random.random() < explorationProb:\n",
    "            idx = random.randint(0, len(board_list) - 1)\n",
    "            game_score = board_list[idx][2]\n",
    "            last_grid1 = board_list[idx][0]\n",
    "            last_grid2 = boards[idx]\n",
    "        else:\n",
    "            game_score = best_score\n",
    "            last_grid1 = best_grid1\n",
    "            last_grid2 = best_grid2\n",
    "        \n",
    "    return game_len, 2**grid_array.max(), game_score, last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "weight_decay = 0\n",
    "beta1 = 0.9\n",
    "\n",
    "model = NN2048().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(beta1, 0.999))\n",
    "loss=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "experiment_dir = \"model\"\n",
    "\n",
    "def save_model(state, filename='model.pth.tar'):\n",
    "    filename = os.path.join(experiment_dir, filename)\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "def load_model(model, optimizer, checkpoint_path, model_only = False):\n",
    "    ckpt_dict = torch.load(checkpoint_path, map_location=\"cuda:0\")\n",
    "\n",
    "    model.load_state_dict(ckpt_dict['state_dict'])\n",
    "    if not model_only:\n",
    "        optimizer.load_state_dict(ckpt_dict['optimizer'])\n",
    "        epoch = ckpt_dict['epoch']\n",
    "        running_mean = ckpt_dict['running_mean']\n",
    "    else:\n",
    "        epoch = None\n",
    "        running_mean = None\n",
    "    return model, optimizer, epoch, running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #  1 Game length  173 Max score  128 Game score  1568\n",
      "Game #  2 Game length  518 Max score  512 Game score  7032\n",
      "Game #  3 Game length  250 Max score  256 Game score  2784\n",
      "Game #  4 Game length  264 Max score  256 Game score  2992\n",
      "Game #  5 Game length  300 Max score  256 Game score  3376\n",
      "Game #  6 Game length  207 Max score  256 Game score  2268\n",
      "Game #  7 Game length  178 Max score  128 Game score  1668\n",
      "Game #  8 Game length  303 Max score  256 Game score  3452\n",
      "Game #  9 Game length  421 Max score  512 Game score  5676\n",
      "Game #  10 Game length  171 Max score  128 Game score  1572\n",
      "Game #  11 Game length  221 Max score  128 Game score  2224\n",
      "Game #  12 Game length  418 Max score  512 Game score  5648\n",
      "Game #  13 Game length  403 Max score  256 Game score  4744\n",
      "Game #  14 Game length  336 Max score  256 Game score  3736\n",
      "Game #  15 Game length  524 Max score  512 Game score  7184\n",
      "Game #  16 Game length  549 Max score  512 Game score  7416\n",
      "Game #  17 Game length  292 Max score  256 Game score  3296\n",
      "Game #  18 Game length  665 Max score  512 Game score  8888\n",
      "Game #  19 Game length  364 Max score  256 Game score  4164\n",
      "Game #  20 Game length  848 Max score  1024 Game score  13164\n",
      "Game #  21 Game length  303 Max score  256 Game score  3460\n",
      "Game #  22 Game length  570 Max score  512 Game score  7660\n",
      "Game #  23 Game length  780 Max score  512 Game score  11312\n",
      "Game #  24 Game length  534 Max score  512 Game score  7276\n",
      "Game #  25 Game length  878 Max score  1024 Game score  13396\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e0f594785254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-e0f594785254>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss, epoch, running_mean)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mgame_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sample_and_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Game # '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Game length '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Max score '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Game score '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7109fcd6a49d>\u001b[0m in \u001b[0;36mgen_sample_and_learn\u001b[0;34m(model, optimizer, loss_fn, is_train, explorationProb)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mlast_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2190\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1500\n",
    "best_model = None\n",
    "\n",
    "def train(model, optimizer, loss, epoch = 0, running_mean = 2048):\n",
    "    ls = [1024] * 10\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, max_score, game_score, last_loss = gen_sample_and_learn(model, optimizer, loss, True, 0)\n",
    "        print ('Game # ', epoch, 'Game length ', game_len, 'Max score ', max_score, 'Game score ', game_score, flush=True)\n",
    "        ls.pop(0)\n",
    "        ls.append(max_score)\n",
    "        if sum(ls) / 10 > running_mean:\n",
    "            running_mean = sum(ls) / 10\n",
    "            filename = \"model_step_\"+str(epoch // 100)+\".pth.tar\"\n",
    "            save_model({\n",
    "                'epoch': epoch,\n",
    "                'running_mean': running_mean,\n",
    "                'state_dict': model.cpu().state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, filename)\n",
    "            best_model, _, _, _ = load_model(model, optimizer, filename, True)\n",
    "            model.cuda()\n",
    "            \n",
    "train(model, optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #  1 Game length  831 Max score  1024 Game score  12940\n",
      "Game #  2 Game length  908 Max score  1024 Game score  14636\n",
      "Game #  3 Game length  924 Max score  1024 Game score  14744\n",
      "Game #  4 Game length  1028 Max score  1024 Game score  16352\n",
      "Game #  5 Game length  929 Max score  1024 Game score  14808\n",
      "Game #  6 Game length  551 Max score  512 Game score  7452\n",
      "Game #  7 Game length  547 Max score  512 Game score  7392\n",
      "Game #  8 Game length  1010 Max score  1024 Game score  16028\n",
      "Game #  9 Game length  534 Max score  512 Game score  7288\n",
      "Game #  10 Game length  693 Max score  1024 Game score  10872\n",
      "Game #  11 Game length  1033 Max score  1024 Game score  16360\n",
      "Game #  12 Game length  800 Max score  1024 Game score  12440\n",
      "Game #  13 Game length  562 Max score  512 Game score  7532\n",
      "Game #  14 Game length  1316 Max score  2048 Game score  23796\n",
      "Game #  15 Game length  795 Max score  1024 Game score  12460\n",
      "Game #  16 Game length  1029 Max score  1024 Game score  16384\n",
      "Game #  17 Game length  810 Max score  1024 Game score  12564\n",
      "Game #  18 Game length  512 Max score  512 Game score  7016\n",
      "Game #  19 Game length  1049 Max score  1024 Game score  16524\n",
      "Game #  20 Game length  853 Max score  1024 Game score  13416\n",
      "Game #  21 Game length  1023 Max score  1024 Game score  16268\n",
      "Game #  22 Game length  1056 Max score  1024 Game score  16600\n",
      "Game #  23 Game length  914 Max score  1024 Game score  14680\n",
      "Game #  24 Game length  513 Max score  512 Game score  7032\n",
      "Game #  25 Game length  913 Max score  1024 Game score  14672\n",
      "Game #  26 Game length  949 Max score  1024 Game score  15032\n",
      "Game #  27 Game length  1040 Max score  1024 Game score  16464\n",
      "Game #  28 Game length  678 Max score  1024 Game score  10744\n",
      "Game #  29 Game length  1300 Max score  2048 Game score  23648\n",
      "Game #  30 Game length  542 Max score  512 Game score  7356\n",
      "Game #  31 Game length  819 Max score  1024 Game score  12828\n",
      "Game #  32 Game length  739 Max score  1024 Game score  11740\n",
      "Game #  33 Game length  574 Max score  512 Game score  7816\n",
      "Game #  34 Game length  961 Max score  1024 Game score  15256\n",
      "Game #  35 Game length  869 Max score  1024 Game score  14056\n",
      "Game #  36 Game length  1048 Max score  1024 Game score  16548\n",
      "Game #  37 Game length  985 Max score  1024 Game score  15776\n",
      "Game #  38 Game length  943 Max score  1024 Game score  14988\n",
      "Game #  39 Game length  868 Max score  1024 Game score  14048\n",
      "Game #  40 Game length  567 Max score  512 Game score  7644\n",
      "Game #  41 Game length  516 Max score  512 Game score  7072\n",
      "Game #  42 Game length  736 Max score  1024 Game score  11476\n",
      "Game #  43 Game length  910 Max score  1024 Game score  14660\n",
      "Game #  44 Game length  487 Max score  512 Game score  6640\n",
      "Game #  45 Game length  537 Max score  512 Game score  7312\n",
      "Game #  46 Game length  524 Max score  512 Game score  7184\n",
      "Game #  47 Game length  842 Max score  1024 Game score  13764\n",
      "Game #  48 Game length  275 Max score  256 Game score  2988\n",
      "Game #  49 Game length  1059 Max score  1024 Game score  16652\n",
      "Game #  50 Game length  1033 Max score  1024 Game score  16392\n",
      "Game #  51 Game length  521 Max score  512 Game score  7072\n",
      "Game #  52 Game length  535 Max score  512 Game score  7292\n",
      "Game #  53 Game length  916 Max score  1024 Game score  14692\n",
      "Game #  54 Game length  735 Max score  1024 Game score  11708\n",
      "Game #  55 Game length  859 Max score  1024 Game score  13916\n",
      "Game #  56 Game length  1004 Max score  1024 Game score  15856\n",
      "Game #  57 Game length  985 Max score  1024 Game score  15748\n",
      "Game #  58 Game length  802 Max score  1024 Game score  12520\n",
      "Game #  59 Game length  817 Max score  1024 Game score  12816\n",
      "Game #  60 Game length  986 Max score  1024 Game score  15756\n",
      "Game #  61 Game length  710 Max score  1024 Game score  11428\n",
      "Game #  62 Game length  540 Max score  512 Game score  7356\n",
      "Game #  63 Game length  1060 Max score  1024 Game score  16632\n",
      "Game #  64 Game length  846 Max score  1024 Game score  13060\n",
      "Game #  65 Game length  859 Max score  1024 Game score  13244\n",
      "Game #  66 Game length  950 Max score  1024 Game score  15036\n",
      "Game #  67 Game length  928 Max score  1024 Game score  14800\n",
      "Game #  68 Game length  1044 Max score  1024 Game score  16496\n",
      "Game #  69 Game length  830 Max score  1024 Game score  12840\n",
      "Game #  70 Game length  892 Max score  1024 Game score  13576\n",
      "Game #  71 Game length  931 Max score  1024 Game score  14828\n",
      "Game #  72 Game length  1047 Max score  1024 Game score  16540\n",
      "Game #  73 Game length  1071 Max score  1024 Game score  16908\n",
      "Game #  74 Game length  519 Max score  512 Game score  7100\n",
      "Game #  75 Game length  967 Max score  1024 Game score  15548\n",
      "Game #  76 Game length  799 Max score  1024 Game score  12492\n",
      "Game #  77 Game length  313 Max score  256 Game score  3528\n",
      "Game #  78 Game length  1296 Max score  2048 Game score  23628\n",
      "Game #  79 Game length  283 Max score  256 Game score  3152\n",
      "Game #  80 Game length  770 Max score  1024 Game score  12240\n",
      "Game #  81 Game length  811 Max score  1024 Game score  12604\n",
      "Game #  82 Game length  1071 Max score  1024 Game score  16908\n",
      "Game #  83 Game length  943 Max score  1024 Game score  14988\n",
      "Game #  84 Game length  991 Max score  1024 Game score  15820\n",
      "Game #  85 Game length  1036 Max score  1024 Game score  16444\n",
      "Game #  86 Game length  743 Max score  1024 Game score  11772\n",
      "Game #  87 Game length  1003 Max score  1024 Game score  15980\n",
      "Game #  88 Game length  1316 Max score  2048 Game score  23820\n",
      "Game #  89 Game length  539 Max score  512 Game score  7340\n",
      "Game #  90 Game length  1057 Max score  1024 Game score  16640\n",
      "Game #  91 Game length  915 Max score  1024 Game score  14684\n",
      "Game #  92 Game length  1042 Max score  1024 Game score  16444\n",
      "Game #  93 Game length  814 Max score  1024 Game score  12620\n",
      "Game #  94 Game length  959 Max score  1024 Game score  15484\n",
      "Game #  95 Game length  825 Max score  1024 Game score  12776\n",
      "Game #  96 Game length  993 Max score  1024 Game score  16000\n",
      "Game #  97 Game length  996 Max score  1024 Game score  15860\n",
      "Game #  98 Game length  1034 Max score  1024 Game score  16396\n",
      "Game #  99 Game length  929 Max score  1024 Game score  14808\n",
      "Game #  100 Game length  805 Max score  1024 Game score  12620\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "def test(model):\n",
    "    epoch = 0\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, max_score, game_score, last_loss = gen_sample_and_learn(model, None, None, False)\n",
    "        print ('Game # ', epoch, 'Game length ', game_len, 'Max score ', max_score, 'Game score ', game_score, flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
