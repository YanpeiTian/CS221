{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN2048(nn.Module):\n",
    "    def __init__(self, input_size=16, filter1=512, filter2=4096, drop_prob=0.):\n",
    "        super(NN2048, self).__init__()\n",
    "        self.conv_a = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(2,1), padding=0)\n",
    "        self.conv_b = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,2), padding=0)\n",
    "        self.conv_aa = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_ab = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.conv_ba = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_bb = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.W_aa = nn.Linear(filter2 * 8, 1)\n",
    "        self.W_ab = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_ba = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_bb = nn.Linear(filter2 * 8, 1)\n",
    "\n",
    "    def flatten(self, x):\n",
    "        N = x.size()[0]\n",
    "        return x.view(N, -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        a = self.relu(self.conv_a(x))\n",
    "        b = self.relu(self.conv_b(x))\n",
    "        aa = self.flatten(self.relu(self.conv_aa(a)))\n",
    "        ab = self.flatten(self.relu(self.conv_ab(a)))\n",
    "        ba = self.flatten(self.relu(self.conv_ba(b)))\n",
    "        bb = self.flatten(self.relu(self.conv_bb(b)))\n",
    "        out = self.W_aa(aa) + self.W_ab(ab) + self.W_ba(ba) + self.W_bb(bb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input(grid):\n",
    "    r = np.zeros(shape=(16, 4, 4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            r[grid[i, j],i, j]=1\n",
    "    return r\n",
    "\n",
    "def add_two(mat):\n",
    "    indexs=np.argwhere(mat==0)\n",
    "    index=np.random.randint(0,len(indexs))\n",
    "    mat[tuple(indexs[index])] = 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleScore=[0,0,4,16,48,128,320,768,1792,4096,9216,20480,45056,98304,212992,458752,983040]\n",
    "moveDict=np.load('move.npy')\n",
    "\n",
    "def move(list):\n",
    "    return moveDict[list[0],list[1],list[2],list[3],:]\n",
    "\n",
    "def lookup(x):\n",
    "    return singleScore[x]\n",
    "\n",
    "lookup = np.vectorize(lookup)\n",
    "\n",
    "def getScore(matrix):\n",
    "    return np.sum(lookup(matrix))\n",
    "\n",
    "def getMove(grid):\n",
    "    board_list = []\n",
    "    for i in range(4):\n",
    "        newGrid=moveGrid(grid, i)\n",
    "        if not isSame(grid,newGrid):\n",
    "            board_list.append((newGrid, i, getScore(newGrid)))\n",
    "    return board_list\n",
    "        \n",
    "def moveGrid(grid,i):\n",
    "    # new=np.zeros((4,4),dtype=np.int)\n",
    "    new = None\n",
    "    if i==0:\n",
    "        # move up\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==1:\n",
    "        # move left\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int)\n",
    "    elif i==2:\n",
    "        # move down\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==3:\n",
    "        # move right\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int)\n",
    "    return new\n",
    "\n",
    "def isSame(grid1,grid2):\n",
    "    return np.all(grid1==grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vchange(grid, v):\n",
    "    g0 = grid\n",
    "    g1 = g0[:,::-1,:]\n",
    "    g2 = g0[:,:,::-1]\n",
    "    g3 = g2[:,::-1,:]\n",
    "    r0 = grid.swapaxes(1,2)\n",
    "    r1 = r0[:,::-1,:]\n",
    "    r2 = r0[:,:,::-1]\n",
    "    r3 = r2[:,::-1,:]\n",
    "    xtrain = np.array([g0,g1,g2,g3,r0,r1,r2,r3])\n",
    "    ytrain = np.array([v]*8)\n",
    "    return xtrain, ytrain\n",
    "\n",
    "def gen_sample_and_learn(model, optimizer, loss_fn, is_train = False, explorationProb=0.1):\n",
    "    model.eval()\n",
    "    game_len = 0\n",
    "    game_score = 0\n",
    "    last_grid1 = np.zeros((4,4),dtype=np.int)\n",
    "    last_grid1 = add_two(last_grid1)\n",
    "    last_grid2 = make_input(last_grid1)\n",
    "    last_loss = 0\n",
    "\n",
    "    while True:\n",
    "        grid_array = add_two(last_grid1)\n",
    "        board_list = getMove(grid_array)\n",
    "        if board_list:\n",
    "            boards = np.array([make_input(g) for g,m,s in board_list])\n",
    "            p = model(torch.from_numpy(boards).cuda()).flatten().detach()        \n",
    "            game_len += 1\n",
    "            best_v = None\n",
    "            for i, (g,m,s) in enumerate(board_list):\n",
    "                v = (s - game_score) + p[i].item()\n",
    "                if best_v is None or v > best_v:\n",
    "                    best_v = v\n",
    "                    best_score = s\n",
    "                    best_grid1 = board_list[i][0]\n",
    "                    best_grid2 = boards[i]\n",
    "                    \n",
    "        else:\n",
    "            best_v = 0\n",
    "            best_grid1 = None\n",
    "            best_grid2 = None\n",
    "            \n",
    "        if is_train:\n",
    "            x, y = Vchange(last_grid2, best_v)\n",
    "            x = torch.from_numpy(x).cuda()\n",
    "            y = torch.from_numpy(y).unsqueeze(dim=1).cuda().float()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y) / 2\n",
    "            last_loss = loss.item()\n",
    "            loss.backward()\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "#             if game_len % 30 == 0:\n",
    "#                 print (game_len, last_loss)\n",
    "                \n",
    "        if not board_list:\n",
    "            break\n",
    "            \n",
    "        # gibbs sampling or espilon-greedy\n",
    "        if is_train and random.random() < explorationProb:\n",
    "            idx = random.randint(0, len(board_list) - 1)\n",
    "            game_score = board_list[idx][2]\n",
    "            last_grid1 = board_list[idx][0]\n",
    "            last_grid2 = boards[idx]\n",
    "        else:\n",
    "            game_score = best_score\n",
    "            last_grid1 = best_grid1\n",
    "            last_grid2 = best_grid2\n",
    "        \n",
    "    return game_len, 2**grid_array.max(), game_score, last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 161 128 1484 74637272.0\n",
      "epoch 2 208 128 1996 11621043.0\n",
      "epoch 3 158 128 1456 6250300.0\n",
      "epoch 4 233 128 2368 4457950.5\n",
      "epoch 5 418 512 5652 11269672.0\n",
      "epoch 6 240 128 2432 3352961.0\n",
      "epoch 7 229 256 2528 3913269.0\n",
      "epoch 8 231 256 2564 2083026.5\n",
      "epoch 9 337 256 3808 6051264.5\n",
      "epoch 10 555 512 7484 7848240.5\n",
      "epoch 11 421 256 5112 7212492.5\n",
      "epoch 12 405 512 5472 8995341.0\n",
      "epoch 13 469 512 6248 4431961.0\n",
      "epoch 14 293 256 3304 2544085.25\n",
      "epoch 15 261 256 2976 3569450.5\n",
      "epoch 16 296 256 3344 1650875.5\n",
      "epoch 17 543 512 7384 16167885.0\n",
      "epoch 18 593 512 8024 7118882.0\n",
      "epoch 19 557 512 7552 13999809.0\n",
      "epoch 24 438 512 5828 18028396.0\n",
      "epoch 25 554 512 7528 48800396.0\n",
      "epoch 26 274 256 3156 29821330.0\n",
      "epoch 27 433 512 5776 30421734.0\n",
      "epoch 28 279 256 3180 14801079.0\n",
      "epoch 29 480 512 6232 12242843.0\n",
      "epoch 30 647 512 8956 36532196.0\n",
      "epoch 31 711 1024 11076 94463824.0\n",
      "epoch 32 314 256 3560 57427928.0\n",
      "epoch 33 357 256 4112 20142252.0\n",
      "epoch 34 550 512 7448 39173344.0\n",
      "epoch 35 788 1024 12384 92201664.0\n",
      "epoch 36 417 512 5584 47748600.0\n",
      "epoch 37 734 1024 11700 66201584.0\n",
      "epoch 38 507 512 6988 43669720.0\n",
      "epoch 39 402 512 5456 38343640.0\n",
      "epoch 40 235 256 2572 13685006.0\n",
      "epoch 41 295 256 3324 10193606.0\n",
      "epoch 42 326 256 3672 10200285.0\n",
      "epoch 43 306 256 3420 6687305.0\n",
      "epoch 44 280 256 3224 7576572.0\n",
      "epoch 45 524 512 7212 11072240.0\n",
      "epoch 46 815 1024 12684 159681184.0\n",
      "epoch 50 697 1024 10976 86167728.0\n",
      "epoch 51 316 256 3572 45356800.0\n",
      "epoch 52 914 1024 14680 99041496.0\n",
      "epoch 53 508 512 6896 86636520.0\n",
      "epoch 54 572 512 7684 119628648.0\n",
      "epoch 55 423 512 5628 69958096.0\n",
      "epoch 56 433 256 5392 65204144.0\n",
      "epoch 57 674 1024 10708 84321328.0\n",
      "epoch 58 815 1024 12684 93962016.0\n",
      "epoch 59 418 512 5592 81234456.0\n",
      "epoch 60 444 512 5884 49822496.0\n",
      "epoch 61 540 512 7356 45015952.0\n",
      "epoch 62 296 256 3328 23814908.0\n",
      "epoch 63 560 512 7692 44939372.0\n",
      "epoch 64 552 512 7432 23065352.0\n",
      "epoch 65 514 512 7064 52480076.0\n",
      "epoch 66 207 128 1932 20360830.0\n",
      "epoch 67 822 1024 12880 108075312.0\n",
      "epoch 68 411 512 5516 69022720.0\n",
      "epoch 69 700 1024 11004 82532024.0\n",
      "epoch 70 923 1024 14764 210814080.0\n",
      "epoch 71 543 512 7372 161185008.0\n",
      "epoch 72 312 256 3644 94826704.0\n",
      "epoch 73 572 512 7708 61321612.0\n",
      "epoch 74 218 256 2432 65232960.0\n",
      "epoch 75 566 512 7612 29947240.0\n",
      "epoch 76 354 256 4312 42884392.0\n",
      "epoch 77 566 512 7640 50213980.0\n",
      "epoch 78 494 512 6784 79213696.0\n",
      "epoch 79 920 1024 14720 208154592.0\n",
      "epoch 80 600 512 8348 382367680.0\n",
      "epoch 81 406 256 5008 201401152.0\n",
      "epoch 82 943 1024 15352 559901568.0\n",
      "epoch 83 288 256 3276 205423072.0\n",
      "epoch 84 417 512 5584 141525648.0\n",
      "epoch 85 514 512 7120 124736000.0\n",
      "epoch 86 532 512 7292 119881112.0\n",
      "epoch 87 519 512 7184 129720472.0\n",
      "epoch 88 926 1024 14792 199976512.0\n",
      "epoch 89 541 512 7324 170152032.0\n",
      "epoch 90 565 512 7608 117770288.0\n",
      "epoch 91 539 512 7340 153917824.0\n",
      "epoch 92 618 512 8672 200650816.0\n",
      "epoch 93 534 512 7288 187322880.0\n",
      "epoch 94 771 1024 12200 343028832.0\n",
      "epoch 95 620 512 9068 536118144.0\n",
      "epoch 96 429 512 5744 248729552.0\n",
      "epoch 97 309 256 3616 151195424.0\n",
      "epoch 98 816 1024 12812 331838752.0\n",
      "epoch 99 720 1024 11340 379104832.0\n",
      "epoch 100 504 512 6876 439613248.0\n",
      "epoch 101 500 512 6940 316536960.0\n",
      "epoch 102 766 1024 12160 369636320.0\n",
      "epoch 103 355 512 4820 338565312.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3101a3542bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN2048\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3101a3542bd1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mgame_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sample_and_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d25ed093a079>\u001b[0m in \u001b[0;36mgen_sample_and_learn\u001b[0;34m(model, optimizer, loss_fn, is_train, explorationProb)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mboard_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mboards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmake_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboard_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mgame_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mbest_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "lr = 1e-3\n",
    "weight_decay = 0#1e-5\n",
    "\n",
    "def train(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.5, 0.999))\n",
    "    loss=nn.MSELoss()\n",
    "    epoch = 0\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, max_score, game_score, last_loss = gen_sample_and_learn(model, optimizer, loss, True)\n",
    "        print ('epoch', epoch, game_len, max_score, game_score, last_loss)\n",
    "    \n",
    "model = NN2048().cuda()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 556 512 7536 0\n",
      "epoch 2 411 512 5544 0\n",
      "epoch 3 561 512 7600 0\n",
      "epoch 4 946 1024 15004 0\n",
      "epoch 5 530 512 7244 0\n",
      "epoch 6 548 512 7468 0\n",
      "epoch 7 1502 2048 27080 0\n",
      "epoch 8 1068 1024 16712 0\n",
      "epoch 9 726 1024 11408 0\n",
      "epoch 10 994 1024 15920 0\n",
      "epoch 11 602 512 8108 0\n",
      "epoch 12 612 512 8432 0\n",
      "epoch 13 492 512 6764 0\n",
      "epoch 14 575 512 7696 0\n",
      "epoch 15 1068 1024 16880 0\n",
      "epoch 16 289 256 3280 0\n",
      "epoch 17 549 512 7584 0\n",
      "epoch 18 407 512 5484 0\n",
      "epoch 19 987 1024 15800 0\n",
      "epoch 20 1041 1024 16480 0\n",
      "epoch 21 845 1024 13120 0\n",
      "epoch 22 507 512 6892 0\n",
      "epoch 23 505 512 6880 0\n",
      "epoch 24 527 512 7240 0\n",
      "epoch 25 515 512 7068 0\n",
      "epoch 26 1033 1024 16416 0\n",
      "epoch 27 859 1024 13244 0\n",
      "epoch 28 1023 1024 16268 0\n",
      "epoch 29 1233 1024 19800 0\n",
      "epoch 30 814 1024 12652 0\n",
      "epoch 31 1324 1024 20896 0\n",
      "epoch 32 595 512 8044 0\n",
      "epoch 33 811 1024 12652 0\n",
      "epoch 34 511 512 7044 0\n",
      "epoch 35 652 512 9020 0\n",
      "epoch 36 541 512 7360 0\n",
      "epoch 37 1066 1024 16844 0\n",
      "epoch 38 277 256 3168 0\n",
      "epoch 39 549 512 7416 0\n",
      "epoch 40 787 1024 12380 0\n",
      "epoch 41 540 512 7332 0\n",
      "epoch 42 342 512 4704 0\n",
      "epoch 43 566 512 7612 0\n",
      "epoch 44 1044 1024 16488 0\n",
      "epoch 45 1035 1024 16428 0\n",
      "epoch 46 993 1024 15832 0\n",
      "epoch 47 306 256 3476 0\n",
      "epoch 48 989 1024 15800 0\n",
      "epoch 49 1271 2048 23256 0\n",
      "epoch 50 1010 1024 16152 0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "def test(model):\n",
    "    epoch = 0\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, max_score, game_score, last_loss = gen_sample_and_learn(model, None, None, False)\n",
    "        print ('epoch', epoch, game_len, max_score, game_score, last_loss)\n",
    "\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
