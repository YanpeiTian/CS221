{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN2048(nn.Module):\n",
    "    def __init__(self, input_size=16, filter1=512, filter2=4096, drop_prob=0.):\n",
    "        super(NN2048, self).__init__()\n",
    "        self.conv_a = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(2,1), padding=0)\n",
    "        self.conv_b = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,2), padding=0)\n",
    "        self.conv_aa = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_ab = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.conv_ba = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_bb = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.W_aa = nn.Linear(filter2 * 8, 1)\n",
    "        self.W_ab = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_ba = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_bb = nn.Linear(filter2 * 8, 1)\n",
    "\n",
    "    def flatten(self, x):\n",
    "        N = x.size()[0]\n",
    "        return x.view(N, -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        a = self.relu(self.conv_a(x))\n",
    "        b = self.relu(self.conv_b(x))\n",
    "        aa = self.flatten(self.relu(self.conv_aa(a)))\n",
    "        ab = self.flatten(self.relu(self.conv_ab(a)))\n",
    "        ba = self.flatten(self.relu(self.conv_ba(b)))\n",
    "        bb = self.flatten(self.relu(self.conv_bb(b)))\n",
    "        out = self.W_aa(aa) + self.W_ab(ab) + self.W_ba(ba) + self.W_bb(bb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input(grid):\n",
    "    r = np.zeros(shape=(16, 4, 4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            r[grid[i, j],i, j]=1\n",
    "    return r\n",
    "\n",
    "def add_two(mat):\n",
    "    indexs=np.argwhere(mat==0)\n",
    "    index=np.random.randint(0,len(indexs))\n",
    "    mat[tuple(indexs[index])] = 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleScore=[0,0,4,16,48,128,320,768,1792,4096,9216,20480,45056,98304,212992,458752,983040]\n",
    "moveDict=np.load('move.npy')\n",
    "\n",
    "def move(list):\n",
    "    return moveDict[list[0],list[1],list[2],list[3],:]\n",
    "\n",
    "def lookup(x):\n",
    "    return singleScore[x]\n",
    "\n",
    "lookup = np.vectorize(lookup)\n",
    "\n",
    "def getScore(matrix):\n",
    "    return np.sum(lookup(matrix))\n",
    "\n",
    "def getMove(grid):\n",
    "    board_list = []\n",
    "    for i in range(4):\n",
    "        newGrid=moveGrid(grid, i)\n",
    "        if not isSame(grid,newGrid):\n",
    "            board_list.append((newGrid, i, getScore(newGrid)))\n",
    "    return board_list\n",
    "        \n",
    "def moveGrid(grid,i):\n",
    "    # new=np.zeros((4,4),dtype=np.int)\n",
    "    new = None\n",
    "    if i==0:\n",
    "        # move up\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==1:\n",
    "        # move left\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int)\n",
    "    elif i==2:\n",
    "        # move down\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==3:\n",
    "        # move right\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int)\n",
    "    return new\n",
    "\n",
    "def isSame(grid1,grid2):\n",
    "    return np.all(grid1==grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vchange(grid, v):\n",
    "    g0 = grid\n",
    "    g1 = g0[:,::-1,:]\n",
    "    g2 = g0[:,:,::-1]\n",
    "    g3 = g2[:,::-1,:]\n",
    "    r0 = grid.swapaxes(1,2)\n",
    "    r1 = r0[:,::-1,:]\n",
    "    r2 = r0[:,:,::-1]\n",
    "    r3 = r2[:,::-1,:]\n",
    "    xtrain = np.array([g0,g1,g2,g3,r0,r1,r2,r3])\n",
    "    ytrain = np.array([v]*8)\n",
    "    return xtrain, ytrain\n",
    "\n",
    "def gen_sample_and_learn(model, optimizer, loss_fn, is_train = False, explorationProb=0.1):\n",
    "    model.eval()\n",
    "    game_len = 0\n",
    "    game_score = 0\n",
    "    last_grid1 = np.zeros((4,4),dtype=np.int)\n",
    "    last_grid1 = add_two(last_grid1)\n",
    "    last_grid2 = make_input(last_grid1)\n",
    "    last_loss = 0\n",
    "\n",
    "    while True:\n",
    "        grid_array = add_two(last_grid1)\n",
    "        board_list = getMove(grid_array)\n",
    "        if board_list:\n",
    "            boards = np.array([make_input(g) for g,m,s in board_list])\n",
    "            p = model(torch.from_numpy(boards).cuda()).flatten().detach()        \n",
    "            game_len += 1\n",
    "            best_v = None\n",
    "            for i, (g,m,s) in enumerate(board_list):\n",
    "                v = (s - game_score) + p[i].item()\n",
    "                if best_v is None or v > best_v:\n",
    "                    best_v = v\n",
    "                    best_score = s\n",
    "                    best_grid1 = board_list[i][0]\n",
    "                    best_grid2 = boards[i]\n",
    "                    \n",
    "        else:\n",
    "            best_v = 0\n",
    "            best_grid1 = None\n",
    "            best_grid2 = None\n",
    "            \n",
    "        if is_train:\n",
    "            x, y = Vchange(last_grid2, best_v)\n",
    "            x = torch.from_numpy(x).cuda()\n",
    "            y = torch.from_numpy(y).unsqueeze(dim=1).cuda().float()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y) / 2\n",
    "            last_loss = loss.item()\n",
    "            loss.backward()\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "#             if game_len % 30 == 0:\n",
    "#                 print (game_len, last_loss)\n",
    "                \n",
    "        if not board_list:\n",
    "            break\n",
    "            \n",
    "        # gibbs sampling or espilon-greedy\n",
    "        if is_train and random.random() < explorationProb:\n",
    "            idx = random.randint(0, len(board_list) - 1)\n",
    "            game_score = board_list[idx][2]\n",
    "            last_grid1 = board_list[idx][0]\n",
    "            last_grid2 = boards[idx]\n",
    "        else:\n",
    "            game_score = best_score\n",
    "            last_grid1 = best_grid1\n",
    "            last_grid2 = best_grid2\n",
    "        \n",
    "    return game_len, 2**grid_array.max(), game_score, last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 49 16 212 93984008.0\n",
      "epoch 2 56 32 276 32837932.0\n",
      "epoch 3 145 128 1280 20333610.0\n",
      "epoch 4 252 256 2892 13693707.0\n",
      "epoch 5 169 128 1536 6876679.0\n",
      "epoch 6 235 256 2596 7587551.5\n",
      "epoch 7 256 256 2804 6260245.0\n",
      "epoch 8 173 128 1616 3590983.5\n",
      "epoch 9 239 256 2676 5148109.5\n",
      "epoch 10 300 256 3388 5916302.5\n",
      "epoch 11 183 128 1716 3507420.0\n",
      "epoch 12 400 512 5436 46665300.0\n",
      "epoch 13 304 256 3456 2604823.5\n",
      "epoch 14 199 128 1852 1659635.125\n",
      "epoch 15 290 256 3312 2937072.5\n",
      "epoch 16 170 128 1544 1648810.5\n",
      "epoch 17 171 128 1548 1426353.75\n",
      "epoch 18 152 128 1340 1048996.0\n",
      "epoch 19 169 128 1564 1056216.0\n",
      "epoch 20 245 256 2720 1809762.375\n",
      "epoch 21 252 256 2768 3334911.75\n",
      "epoch 22 186 128 1760 1546501.5\n",
      "epoch 23 440 512 5824 3908763.5\n",
      "epoch 24 218 256 2432 4348224.0\n",
      "epoch 25 271 256 3136 7297278.0\n",
      "epoch 26 157 128 1424 2057486.75\n",
      "epoch 27 143 128 1328 2132903.5\n",
      "epoch 28 369 512 4992 146960384.0\n",
      "epoch 29 242 256 2704 35943352.0\n",
      "epoch 30 287 256 3272 24968008.0\n",
      "epoch 31 302 256 3400 15314310.0\n",
      "epoch 32 165 128 1532 9934622.0\n",
      "epoch 33 288 256 3264 6913313.0\n",
      "epoch 34 398 256 4920 12751986.0\n",
      "epoch 35 282 256 3208 19405404.0\n",
      "epoch 36 448 512 5880 26503662.0\n",
      "epoch 37 348 256 4000 20719512.0\n",
      "epoch 38 249 256 2696 11229729.0\n",
      "epoch 39 252 256 2892 16839262.0\n",
      "epoch 40 400 512 5408 79574704.0\n",
      "epoch 41 188 128 1756 10035763.0\n",
      "epoch 42 214 256 2400 22995284.0\n",
      "epoch 43 527 512 7180 27129920.0\n",
      "epoch 44 193 128 1808 9911162.0\n",
      "epoch 45 435 512 5788 17512856.0\n",
      "epoch 46 307 256 3484 16089479.0\n",
      "epoch 47 318 256 3592 14641473.0\n",
      "epoch 48 226 256 2512 11946488.0\n",
      "epoch 49 377 512 5084 63335336.0\n",
      "epoch 50 422 512 5612 193145952.0\n",
      "epoch 51 301 256 3368 62014632.0\n",
      "epoch 52 295 256 3324 43254260.0\n",
      "epoch 53 362 256 4364 42115864.0\n",
      "epoch 54 287 256 3260 29423494.0\n",
      "epoch 55 464 512 6436 116500104.0\n",
      "epoch 56 297 256 3336 37548368.0\n",
      "epoch 57 260 128 2636 54128328.0\n",
      "epoch 58 303 256 3404 53906512.0\n",
      "epoch 59 396 512 5356 93015024.0\n",
      "epoch 60 484 512 6624 65147960.0\n",
      "epoch 61 532 512 7264 429323136.0\n",
      "epoch 62 311 256 3544 195645952.0\n",
      "epoch 63 374 256 4560 111163016.0\n",
      "epoch 64 514 512 7072 179535328.0\n",
      "epoch 65 540 512 7356 876744320.0\n",
      "epoch 66 551 512 7452 2640645632.0\n",
      "epoch 67 304 256 3496 2199100672.0\n",
      "epoch 68 281 256 3228 876821504.0\n",
      "epoch 69 308 256 3612 535859072.0\n",
      "epoch 70 428 512 5692 565755904.0\n",
      "epoch 71 399 256 4924 515321600.0\n",
      "epoch 72 301 256 3812 588923776.0\n",
      "epoch 73 302 256 3388 277992160.0\n",
      "epoch 74 518 512 7144 477508032.0\n",
      "epoch 75 471 512 6268 828932864.0\n",
      "epoch 76 283 256 3240 814087808.0\n",
      "epoch 77 465 512 6224 657559680.0\n",
      "epoch 78 290 256 3288 369219904.0\n",
      "epoch 79 351 256 4028 212080144.0\n",
      "epoch 80 457 512 6144 410393312.0\n",
      "epoch 81 569 512 7640 428022432.0\n",
      "epoch 82 447 512 5888 389137728.0\n",
      "epoch 83 646 512 8940 1163335424.0\n",
      "epoch 84 535 512 7292 1287888640.0\n",
      "epoch 85 225 128 2256 669161664.0\n",
      "epoch 86 458 512 6092 601193024.0\n",
      "epoch 87 293 256 3304 474579360.0\n",
      "epoch 88 402 512 5456 496713888.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "lr = 1e-3\n",
    "weight_decay = 0#1e-5\n",
    "\n",
    "def train(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.5, 0.999))\n",
    "    loss=nn.MSELoss()\n",
    "    epoch = 0\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, max_score, game_score, last_loss = gen_sample_and_learn(model, optimizer, loss, True)\n",
    "        print ('epoch', epoch, game_len, max_score, game_score, last_loss)\n",
    "        \n",
    "def test(model):\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, max_score, game_score, last_loss = gen_sample_and_learn(model, optimizer, loss, False)\n",
    "        print ('epoch', epoch, game_len, max_score, game_score, last_loss)\n",
    "    \n",
    "model = NN2048().cuda()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
