{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN2048(nn.Module):\n",
    "    def __init__(self, input_size=16, filter1=512, filter2=4096, drop_prob=0.):\n",
    "        super(NN2048, self).__init__()\n",
    "        self.conv_a = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(2,1), padding=0)\n",
    "        self.conv_b = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,2), padding=0)\n",
    "        self.conv_aa = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_ab = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.conv_ba = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_bb = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.W_aa = nn.Linear(filter2 * 8, 1)\n",
    "        self.W_ab = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_ba = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_bb = nn.Linear(filter2 * 8, 1)\n",
    "\n",
    "    def flatten(self, x):\n",
    "        N = x.size()[0]\n",
    "        return x.view(N, -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        a = self.relu(self.conv_a(x))\n",
    "        b = self.relu(self.conv_b(x))\n",
    "        aa = self.flatten(self.relu(self.conv_aa(a)))\n",
    "        ab = self.flatten(self.relu(self.conv_ab(a)))\n",
    "        ba = self.flatten(self.relu(self.conv_ba(b)))\n",
    "        bb = self.flatten(self.relu(self.conv_bb(b)))\n",
    "        out = self.W_aa(aa) + self.W_ab(ab) + self.W_ba(ba) + self.W_bb(bb)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleScore=[0,0,4,16,48,128,320,768,1792,4096,9216,20480,45056,98304,212992,458752,983040]\n",
    "moveDict=np.load('move.npy')\n",
    "\n",
    "def add_two(mat):\n",
    "    indexs=np.argwhere(mat==0)\n",
    "    index=np.random.randint(0,len(indexs))\n",
    "    mat[tuple(indexs[index])] = 1\n",
    "    return mat\n",
    "\n",
    "def game_state(mat):\n",
    "    return 'not over' if np.any(mat == 0) or np.any(mat[:, 0:-1]==mat[:, 1:]) or np.any(mat[0:-1, :]==mat[1:, :]) else 'lose'\n",
    "\n",
    "def move(list):\n",
    "    return moveDict[list[0],list[1],list[2],list[3],:]\n",
    "\n",
    "def lookup(x):\n",
    "    return singleScore[x]\n",
    "\n",
    "lookup = np.vectorize(lookup)\n",
    "\n",
    "def getScore(matrix):\n",
    "    return np.sum(lookup(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMove(grid):\n",
    "    board_list = []\n",
    "    for i in range(4):\n",
    "        newGrid=moveGrid(grid, i)\n",
    "        if not isSame(grid,newGrid):\n",
    "            board_list.append((i, newGrid, getScore(newGrid)))\n",
    "    return board_list\n",
    "        \n",
    "def moveGrid(grid,i):\n",
    "    # new=np.zeros((4,4),dtype=np.int)\n",
    "    new = None\n",
    "    if i==0:\n",
    "        # move up\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==1:\n",
    "        # move left\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int)\n",
    "    elif i==2:\n",
    "        # move down\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==3:\n",
    "        # move right\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int)\n",
    "    return new\n",
    "\n",
    "def isSame(grid1,grid2):\n",
    "    return np.all(grid1==grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input(grid):\n",
    "    r = np.zeros(shape=(16, 4, 4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            r[grid[i, j], i, j]=1\n",
    "    return r\n",
    "\n",
    "def Vchange(grid, v):\n",
    "    g0 = grid\n",
    "    g1 = g0[:,::-1,:]\n",
    "    g2 = g0[:,:,::-1]\n",
    "    g3 = g2[:,::-1,:]\n",
    "    r0 = grid.swapaxes(1,2)\n",
    "    r1 = r0[:,::-1,:]\n",
    "    r2 = r0[:,:,::-1]\n",
    "    r3 = r2[:,::-1,:]\n",
    "    xtrain = np.array([g0,g1,g2,g3,r0,r1,r2,r3])\n",
    "    ytrain = np.array([v]*8) \n",
    "    return torch.from_numpy(xtrain), \\\n",
    "            torch.from_numpy(ytrain).float()#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sample_and_learn(model, optimizer, loss_fn, is_train = False, explorationProb=0.2):\n",
    "    model.eval()\n",
    "    game_len = 0\n",
    "    last_loss = 0\n",
    "    last_grid = np.zeros((4,4),dtype=np.int)\n",
    "    last_grid = add_two(last_grid)\n",
    "    pre_score = 0\n",
    "    \n",
    "    while True:\n",
    "        matrix = add_two(last_grid) #use last_grid before adding two??\n",
    "        board_list = getMove(matrix)\n",
    "        \n",
    "        if len(board_list) == 0:\n",
    "            assert(game_state(last_grid)=='lose')\n",
    "            best_v = 0\n",
    "            best_grid = None\n",
    "        else:\n",
    "            game_len += 1\n",
    "            best_v = None\n",
    "            boards = torch.from_numpy(np.array([make_input(g) for m, g, s in board_list], dtype=np.float))\n",
    "            preds = model(boards)\n",
    "            for (move, newGrid, score), pred  in zip(board_list, preds):\n",
    "                v = score - pre_score + pred\n",
    "#                 print ('score', score - pre_score)\n",
    "                if best_v is None or v > best_v:\n",
    "                    best_v = v\n",
    "                    best_score = score\n",
    "                    best_grid = newGrid\n",
    "                    \n",
    "        if is_train:\n",
    "            x, y = Vchange(make_input(last_grid), best_v.item())\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "#             print (pred)\n",
    "            loss = loss_fn(pred, y) / 2\n",
    "            loss.backward()\n",
    "            last_loss = loss.item()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "        \n",
    "        if best_grid is None:\n",
    "            break\n",
    "        \n",
    "        if game_len % 20 == 0:\n",
    "            print ('game length',game_len, last_loss, best_score, best_v)\n",
    "        \n",
    "        # gibbs sampling or espilon-greedy\n",
    "        if is_train and random.random() < explorationProb:\n",
    "            (_, last_grid, pre_score) = random.choice(board_list)\n",
    "        else:\n",
    "            last_grid = best_grid\n",
    "            pre_score = best_score\n",
    "            \n",
    "    return game_len, last_loss, last_grid, pre_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0732], grad_fn=<AddBackward0>)\n",
      "[[1 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "tensor([12.6450], grad_fn=<AddBackward0>)\n",
      "[[0 0 0 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]]\n",
      "tensor([23.7404], grad_fn=<AddBackward0>)\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 2]]\n",
      "tensor([55.1405], grad_fn=<AddBackward0>)\n",
      "[[1 0 1 2]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "tensor([101.8547], grad_fn=<AddBackward0>)\n",
      "[[1 0 2 2]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-6711b58f874e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN2048\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-6711b58f874e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mgame_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sample_and_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-6c80cc2331b4>\u001b[0m in \u001b[0;36mgen_sample_and_learn\u001b[0;34m(model, optimizer, loss_fn, is_train, explorationProb)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mlast_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs221/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs221/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;34mr\"\"\"See :func:`torch.norm`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs221/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"nuc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.5, 0.999))\n",
    "    loss=nn.MSELoss()\n",
    "    epoch = 0\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, last_loss, last_grid, pre_score = gen_sample_and_learn(model, optimizer, loss, True, 0)\n",
    "        print ('epoch', epoch, game_len, last_loss, last_grid, pre_score)\n",
    "        \n",
    "def test(model):\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, last_loss, last_grid, pre_score = gen_sample_and_learn(model, optimizer, loss, False)\n",
    "        print ('epoch', epoch, game_len, last_loss, last_grid, pre_score)\n",
    "    \n",
    "model = NN2048()\n",
    "train(model)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
