{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from c2048log import Game, push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN2048(nn.Module):\n",
    "    def __init__(self, input_size=16, filter1=512, filter2=4096, drop_prob=0.):\n",
    "        super(NN2048, self).__init__()\n",
    "#         self.conv_a2 = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(2,2), padding=0)\n",
    "#         self.conv_a3 = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(3,3), padding=0)\n",
    "#         self.conv_a4 = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(4,4), padding=0)\n",
    "#         self.conv_b2 = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,2), padding=0)\n",
    "#         self.conv_b3 = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,3), padding=0)\n",
    "#         self.conv_b4 = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,4), padding=0)\n",
    "        self.conv_a = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(2,1), padding=0)\n",
    "        self.conv_b = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,2), padding=0)\n",
    "        self.conv_aa = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_ab = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.conv_ba = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_bb = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.W_aa = nn.Linear(filter2 * 8, 1)\n",
    "        self.W_ab = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_ba = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_bb = nn.Linear(filter2 * 8, 1)\n",
    "\n",
    "    def flatten(self, x):\n",
    "        N = x.size()[0]\n",
    "        return x.view(N, -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        a = self.relu(self.conv_a(x))\n",
    "        b = self.relu(self.conv_b(x))\n",
    "        aa = self.flatten(self.relu(self.conv_aa(a)))\n",
    "        ab = self.flatten(self.relu(self.conv_ab(a)))\n",
    "        ba = self.flatten(self.relu(self.conv_ba(b)))\n",
    "        bb = self.flatten(self.relu(self.conv_bb(b)))\n",
    "        out = self.W_aa(aa) + self.W_ab(ab) + self.W_ba(ba) + self.W_bb(bb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table ={2**i:i for i in range(1,16)}\n",
    "table[0]=0\n",
    "def make_input(grid):\n",
    "    g0 = grid\n",
    "    r = np.zeros(shape=(16, 4, 4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            v = g0[i, j]\n",
    "            r[table[v],i, j]=1\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_two(mat):\n",
    "    indexs=np.argwhere(mat==0)\n",
    "    index=np.random.randint(0,len(indexs))\n",
    "    mat[tuple(indexs[index])] = 2\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vchange(grid, v):\n",
    "    g0 = grid\n",
    "    g1 = g0[:,::-1,:]\n",
    "    g2 = g0[:,:,::-1]\n",
    "    g3 = g2[:,::-1,:]\n",
    "    r0 = grid.swapaxes(1,2)\n",
    "    r1 = r0[:,::-1,:]\n",
    "    r2 = r0[:,:,::-1]\n",
    "    r3 = r2[:,::-1,:]\n",
    "    xtrain = np.array([g0,g1,g2,g3,r0,r1,r2,r3])\n",
    "    ytrain = np.array([v]*8)\n",
    "    return xtrain, ytrain\n",
    "\n",
    "def gen_sample_and_learn(model, optimizer, loss_fn, is_train = True):\n",
    "    model.eval()\n",
    "    game_len = 0\n",
    "    game_score = 0\n",
    "    last_grid1 = np.zeros((4,4),dtype=np.int)\n",
    "    last_grid1 = add_two(last_grid1)\n",
    "    last_grid2 = make_input(last_grid1)\n",
    "    while True:\n",
    "        grid_array = add_two(last_grid1)\n",
    "        board_list = []\n",
    "        for m in range(4):\n",
    "            g = grid_array.copy()\n",
    "            s = push(g, m%4)\n",
    "            if s >= 0:\n",
    "                board_list.append( (g, m, s) )\n",
    "        if board_list:\n",
    "            boards = np.array([make_input(g) for g,m,s in board_list])\n",
    "            p = model(torch.from_numpy(boards).cuda()).flatten().detach()        \n",
    "            game_len+=1\n",
    "            best_move = -1\n",
    "            best_v = None\n",
    "            for i, (g,m,s) in enumerate(board_list):\n",
    "#                 print (s)\n",
    "                v = 2 * s + p[i].item()\n",
    "                if best_v is None or v > best_v:\n",
    "                    best_v = v\n",
    "                    best_move = m\n",
    "                    best_score = 2 * s\n",
    "                    best_grid1 = board_list[i][0]\n",
    "                    best_grid2 = boards[i]\n",
    "                    \n",
    "            game_score += best_score\n",
    "        else:\n",
    "            best_v = 0\n",
    "            best_grid1 = None\n",
    "            best_grid2 = None\n",
    "            \n",
    "        if is_train:\n",
    "            x, y = Vchange(last_grid2, best_v)\n",
    "            x = torch.from_numpy(x).cuda()\n",
    "            y = torch.from_numpy(y).unsqueeze(dim=1).cuda().float()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            last_loss = loss.item()\n",
    "            loss.backward()\n",
    "#             nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "#             if game_len % 50 == 0:\n",
    "#                 print (game_len, last_loss)\n",
    "                \n",
    "        if not board_list:\n",
    "            break\n",
    "        last_grid2 = best_grid2\n",
    "        last_grid1 = best_grid1\n",
    "        \n",
    "    return game_len, grid_array.max(), game_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "model = NN2048().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.5, 0.999))\n",
    "loss_fn=nn.MSELoss()\n",
    "\n",
    "for j in range(200):\n",
    "    result = gen_sample_and_learn(model, optimizer, loss_fn)\n",
    "    print(j, result)\n",
    "    if result is not None and result[1] >= 4096:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (666, 512, 1243.0)\n",
      "2 (2066, 2048, 4041.0)\n",
      "3 (813, 1024, 1553.0)\n",
      "4 (1391, 1024, 2691.0)\n",
      "5 (1171, 1024, 2256.0)\n",
      "6 (685, 512, 1288.0)\n",
      "7 (1621, 2048, 3153.0)\n",
      "8 (1874, 2048, 3663.0)\n",
      "9 (921, 1024, 1764.0)\n",
      "10 (2177, 2048, 4266.0)\n",
      "11 (591, 512, 1105.0)\n",
      "12 (1284, 1024, 2479.0)\n",
      "13 (1268, 1024, 2450.0)\n",
      "14 (847, 1024, 1616.0)\n",
      "15 (304, 256, 536.0)\n",
      "16 (996, 1024, 1911.0)\n",
      "17 (1573, 2048, 3067.0)\n",
      "18 (1627, 2048, 3160.0)\n",
      "19 (1011, 1024, 1945.0)\n",
      "20 (1142, 1024, 2197.0)\n",
      "21 (1199, 1024, 2313.0)\n",
      "22 (976, 1024, 1875.0)\n",
      "23 (1158, 1024, 2233.0)\n",
      "24 (639, 512, 1201.0)\n",
      "25 (1025, 1024, 1973.0)\n",
      "26 (1686, 2048, 3283.0)\n",
      "27 (561, 512, 1045.0)\n",
      "28 (1732, 2048, 3378.0)\n",
      "29 (1291, 1024, 2496.0)\n",
      "30 (544, 512, 1012.0)\n",
      "31 (1056, 1024, 2027.0)\n",
      "32 (693, 512, 1303.0)\n",
      "33 (855, 1024, 1622.0)\n",
      "34 (588, 512, 1095.0)\n",
      "35 (1227, 1024, 2363.0)\n",
      "36 (1351, 1024, 2616.0)\n",
      "37 (1088, 1024, 2090.0)\n",
      "38 (294, 256, 517.0)\n",
      "39 (1551, 2048, 3019.0)\n",
      "40 (735, 512, 1391.0)\n",
      "41 (808, 512, 1531.0)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "def test(model):\n",
    "    epoch = 0\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        res = gen_sample_and_learn(model, None, None, False)\n",
    "        print (epoch, res)\n",
    "\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
