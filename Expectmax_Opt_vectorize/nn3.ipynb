{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN2048(nn.Module):\n",
    "    def __init__(self, input_size=16, filter1=512, filter2=4096, drop_prob=0.):\n",
    "        super(NN2048, self).__init__()\n",
    "        self.conv_a = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(2,1), padding=0)\n",
    "        self.conv_b = nn.Conv2d(in_channels=input_size, out_channels=filter1, kernel_size=(1,2), padding=0)\n",
    "        self.conv_aa = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_ab = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.conv_ba = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(2,1), padding=0)\n",
    "        self.conv_bb = nn.Conv2d(in_channels=filter1, out_channels=filter2, kernel_size=(1,2), padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.W_aa = nn.Linear(filter2 * 8, 1)\n",
    "        self.W_ab = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_ba = nn.Linear(filter2 * 9, 1)\n",
    "        self.W_bb = nn.Linear(filter2 * 8, 1)\n",
    "\n",
    "    def flatten(self, x):\n",
    "        N = x.size()[0]\n",
    "        return x.view(N, -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        a = self.relu(self.conv_a(x))\n",
    "        b = self.relu(self.conv_b(x))\n",
    "        aa = self.flatten(self.relu(self.conv_aa(a)))\n",
    "        ab = self.flatten(self.relu(self.conv_ab(a)))\n",
    "        ba = self.flatten(self.relu(self.conv_ba(b)))\n",
    "        bb = self.flatten(self.relu(self.conv_bb(b)))\n",
    "        out = self.W_aa(aa) + self.W_ab(ab) + self.W_ba(ba) + self.W_bb(bb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input(grid):\n",
    "    r = np.zeros(shape=(16, 4, 4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            r[grid[i, j],i, j]=1\n",
    "    return r\n",
    "\n",
    "def add_two(mat):\n",
    "    indexs=np.argwhere(mat==0)\n",
    "    index=np.random.randint(0,len(indexs))\n",
    "    mat[tuple(indexs[index])] = 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleScore=[0,0,4,16,48,128,320,768,1792,4096,9216,20480,45056,98304,212992,458752,983040]\n",
    "moveDict=np.load('move.npy')\n",
    "\n",
    "def move(list):\n",
    "    return moveDict[list[0],list[1],list[2],list[3],:]\n",
    "\n",
    "def lookup(x):\n",
    "    return singleScore[x]\n",
    "\n",
    "lookup = np.vectorize(lookup)\n",
    "\n",
    "def getScore(matrix):\n",
    "    return np.sum(lookup(matrix))\n",
    "\n",
    "def getMove(grid):\n",
    "    board_list = []\n",
    "    for i in range(4):\n",
    "        newGrid=moveGrid(grid, i)\n",
    "        if not isSame(grid,newGrid):\n",
    "            board_list.append((newGrid, i, getScore(newGrid)))\n",
    "    return board_list\n",
    "        \n",
    "def moveGrid(grid,i):\n",
    "    # new=np.zeros((4,4),dtype=np.int)\n",
    "    new = None\n",
    "    if i==0:\n",
    "        # move up\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==1:\n",
    "        # move left\n",
    "        new = np.stack([move(grid[row,:]) for row in range(4)], axis = 0).astype(int)\n",
    "    elif i==2:\n",
    "        # move down\n",
    "        grid=np.transpose(grid)\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int).T\n",
    "    elif i==3:\n",
    "        # move right\n",
    "        new = np.stack([np.flip(move(np.flip(grid[row,:]))) for row in range(4)], axis = 0).astype(int)\n",
    "    return new\n",
    "\n",
    "def isSame(grid1,grid2):\n",
    "    return np.all(grid1==grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vchange(grid, v):\n",
    "    g0 = grid\n",
    "    g1 = g0[:,::-1,:]\n",
    "    g2 = g0[:,:,::-1]\n",
    "    g3 = g2[:,::-1,:]\n",
    "    r0 = grid.swapaxes(1,2)\n",
    "    r1 = r0[:,::-1,:]\n",
    "    r2 = r0[:,:,::-1]\n",
    "    r3 = r2[:,::-1,:]\n",
    "    xtrain = np.array([g0,g1,g2,g3,r0,r1,r2,r3])\n",
    "    ytrain = np.array([v]*8)\n",
    "    return xtrain, ytrain\n",
    "\n",
    "def gen_sample_and_learn(model, optimizer, loss_fn, is_train = False, explorationProb=0.1):\n",
    "    model.eval()\n",
    "    game_len = 0\n",
    "    game_score = 0\n",
    "    last_grid1 = np.zeros((4,4),dtype=np.int)\n",
    "    last_grid1 = add_two(last_grid1)\n",
    "    last_grid2 = make_input(last_grid1)\n",
    "    last_loss = 0\n",
    "\n",
    "    while True:\n",
    "        grid_array = add_two(last_grid1)\n",
    "        board_list = getMove(grid_array)\n",
    "        if board_list:\n",
    "            boards = np.array([make_input(g) for g,m,s in board_list])\n",
    "            p = model(torch.from_numpy(boards).cuda()).flatten().detach()        \n",
    "            game_len += 1\n",
    "            best_v = None\n",
    "            for i, (g,m,s) in enumerate(board_list):\n",
    "                v = (s - game_score) + p[i].item()\n",
    "                if best_v is None or v > best_v:\n",
    "                    best_v = v\n",
    "                    best_score = s\n",
    "                    best_grid1 = board_list[i][0]\n",
    "                    best_grid2 = boards[i]\n",
    "                    \n",
    "        else:\n",
    "            best_v = 0\n",
    "            best_grid1 = None\n",
    "            best_grid2 = None\n",
    "            \n",
    "        if is_train:\n",
    "            x, y = Vchange(last_grid2, best_v)\n",
    "            x = torch.from_numpy(x).cuda()\n",
    "            y = torch.from_numpy(y).unsqueeze(dim=1).cuda().float()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y) / 2\n",
    "            last_loss = loss.item()\n",
    "            loss.backward()\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "#             if game_len % 30 == 0:\n",
    "#                 print (game_len, last_loss)\n",
    "                \n",
    "        if not board_list:\n",
    "            break\n",
    "            \n",
    "        # gibbs sampling or espilon-greedy\n",
    "        if is_train and random.random() < explorationProb:\n",
    "            idx = random.randint(0, len(board_list) - 1)\n",
    "            game_score = board_list[idx][2]\n",
    "            last_grid1 = board_list[idx][0]\n",
    "            last_grid2 = boards[idx]\n",
    "        else:\n",
    "            game_score = best_score\n",
    "            last_grid1 = best_grid1\n",
    "            last_grid2 = best_grid2\n",
    "        \n",
    "    return game_len, 2**grid_array.max(), game_score, last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 161 128 1484 74637272.0\n",
      "epoch 2 208 128 1996 11621043.0\n",
      "epoch 3 158 128 1456 6250300.0\n",
      "epoch 4 233 128 2368 4457950.5\n",
      "epoch 5 418 512 5652 11269672.0\n",
      "epoch 6 240 128 2432 3352961.0\n",
      "epoch 7 229 256 2528 3913269.0\n",
      "epoch 8 231 256 2564 2083026.5\n",
      "epoch 9 337 256 3808 6051264.5\n",
      "epoch 10 555 512 7484 7848240.5\n",
      "epoch 11 421 256 5112 7212492.5\n",
      "epoch 12 405 512 5472 8995341.0\n",
      "epoch 13 469 512 6248 4431961.0\n",
      "epoch 14 293 256 3304 2544085.25\n",
      "epoch 15 261 256 2976 3569450.5\n",
      "epoch 16 296 256 3344 1650875.5\n",
      "epoch 17 543 512 7384 16167885.0\n",
      "epoch 18 593 512 8024 7118882.0\n",
      "epoch 19 557 512 7552 13999809.0\n",
      "epoch 24 438 512 5828 18028396.0\n",
      "epoch 25 554 512 7528 48800396.0\n",
      "epoch 26 274 256 3156 29821330.0\n",
      "epoch 27 433 512 5776 30421734.0\n",
      "epoch 28 279 256 3180 14801079.0\n",
      "epoch 29 480 512 6232 12242843.0\n",
      "epoch 30 647 512 8956 36532196.0\n",
      "epoch 31 711 1024 11076 94463824.0\n",
      "epoch 32 314 256 3560 57427928.0\n",
      "epoch 33 357 256 4112 20142252.0\n",
      "epoch 34 550 512 7448 39173344.0\n",
      "epoch 35 788 1024 12384 92201664.0\n",
      "epoch 36 417 512 5584 47748600.0\n",
      "epoch 37 734 1024 11700 66201584.0\n",
      "epoch 38 507 512 6988 43669720.0\n",
      "epoch 39 402 512 5456 38343640.0\n",
      "epoch 40 235 256 2572 13685006.0\n",
      "epoch 41 295 256 3324 10193606.0\n",
      "epoch 42 326 256 3672 10200285.0\n",
      "epoch 43 306 256 3420 6687305.0\n",
      "epoch 44 280 256 3224 7576572.0\n",
      "epoch 45 524 512 7212 11072240.0\n",
      "epoch 46 815 1024 12684 159681184.0\n",
      "epoch 50 697 1024 10976 86167728.0\n",
      "epoch 51 316 256 3572 45356800.0\n",
      "epoch 52 914 1024 14680 99041496.0\n",
      "epoch 53 508 512 6896 86636520.0\n",
      "epoch 54 572 512 7684 119628648.0\n",
      "epoch 55 423 512 5628 69958096.0\n",
      "epoch 56 433 256 5392 65204144.0\n",
      "epoch 57 674 1024 10708 84321328.0\n",
      "epoch 58 815 1024 12684 93962016.0\n",
      "epoch 59 418 512 5592 81234456.0\n",
      "epoch 60 444 512 5884 49822496.0\n",
      "epoch 61 540 512 7356 45015952.0\n",
      "epoch 62 296 256 3328 23814908.0\n",
      "epoch 63 560 512 7692 44939372.0\n",
      "epoch 64 552 512 7432 23065352.0\n",
      "epoch 65 514 512 7064 52480076.0\n",
      "epoch 66 207 128 1932 20360830.0\n",
      "epoch 67 822 1024 12880 108075312.0\n",
      "epoch 68 411 512 5516 69022720.0\n",
      "epoch 69 700 1024 11004 82532024.0\n",
      "epoch 70 923 1024 14764 210814080.0\n",
      "epoch 71 543 512 7372 161185008.0\n",
      "epoch 72 312 256 3644 94826704.0\n",
      "epoch 73 572 512 7708 61321612.0\n",
      "epoch 74 218 256 2432 65232960.0\n",
      "epoch 75 566 512 7612 29947240.0\n",
      "epoch 76 354 256 4312 42884392.0\n",
      "epoch 77 566 512 7640 50213980.0\n",
      "epoch 78 494 512 6784 79213696.0\n",
      "epoch 79 920 1024 14720 208154592.0\n",
      "epoch 80 600 512 8348 382367680.0\n",
      "epoch 81 406 256 5008 201401152.0\n",
      "epoch 82 943 1024 15352 559901568.0\n",
      "epoch 83 288 256 3276 205423072.0\n",
      "epoch 84 417 512 5584 141525648.0\n",
      "epoch 85 514 512 7120 124736000.0\n",
      "epoch 86 532 512 7292 119881112.0\n",
      "epoch 87 519 512 7184 129720472.0\n",
      "epoch 88 926 1024 14792 199976512.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "lr = 1e-3\n",
    "weight_decay = 0#1e-5\n",
    "\n",
    "def train(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.5, 0.999))\n",
    "    loss=nn.MSELoss()\n",
    "    epoch = 0\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, max_score, game_score, last_loss = gen_sample_and_learn(model, optimizer, loss, True, 0)\n",
    "        print ('epoch', epoch, game_len, max_score, game_score, last_loss)\n",
    "    \n",
    "model = NN2048().cuda()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    epoch = 0\n",
    "    while epoch != num_epochs:\n",
    "        epoch += 1\n",
    "        game_len, max_score, game_score, last_loss = gen_sample_and_learn(model, None, None, False)\n",
    "        print ('epoch', epoch, game_len, max_score, game_score, last_loss)\n",
    "\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
